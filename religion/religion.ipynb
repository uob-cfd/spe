{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is religion a good thing?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "As for the other notebooks in this set of assignments, tests in this notebook\n",
    "do not usually test if you have the right answer, but only if you have the\n",
    "*right sort* of answer.  *Be careful* -- the tests could pass, but your answer\n",
    "could still be wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Safe settings for Pandas.\n",
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('religion.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To religion\n",
    "\n",
    "We [return](https://matthew-brett.github.io/cfd2020/chapters/07/noble_politics) to the data\n",
    "published in:\n",
    "\n",
    "> Samuel P. Oliner and Pearl M. Oliner (1992) \"The Altruistic Personality:\n",
    "> Rescuers of Jews in Nazi Europe\". Free Press, New York. ISBN 0-02923829-3.\n",
    "\n",
    "See [the dataset\n",
    "page](https://github.com/matthew-brett/datasets/tree/master/oliner1988)\n",
    "for some more details.\n",
    "\n",
    "As you remember, Samuel and Pearl Oliner had detailed interview data from:\n",
    "\n",
    "* 231 people who had sheltered Jews during the second world war (the *Rescuer*\n",
    "  group);\n",
    "* 53 people, roughly matched with the Rescuers on age, education, and\n",
    "  nationality, who claimed to have either sheltered Jews, or contributed to the\n",
    "  resistance, or both (the *Active* group);\n",
    "* 73 people, roughly matched to the Rescuers as above, who did not claim to\n",
    "  have sheltered Jews or helped the resistance (the *Bystander* group).\n",
    "\n",
    "The Oliners' interest was to find characteristics of the Rescuer group that\n",
    "might be related to their extraordinary choice to risk their lives or\n",
    "livelihood to shelter Jews.\n",
    "\n",
    "Here we are studying the data from table 6.6 of their book. The table\n",
    "cross-tabulates the answers to question D14 from their interview schedule:\n",
    "\"Before the war, were you very religious, somewhat religious, not very\n",
    "religious or not at all religious?\".\n",
    "\n",
    "You will find\n",
    "a [version](https://github.com/matthew-brett/datasets/tree/master/oliner1988)\n",
    "of the data from that table in the file `oliner_tab6_6.csv`.\n",
    "\n",
    "Read that table as a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "religion = ...\n",
    "religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_01_religion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next clean up the table a bit.  First make a new table that contains all but\n",
    "the last row (with level \"out of\") that we do not need.  Next, to make indexing\n",
    "easier, replace the current table index (that is sequential row numbers) with\n",
    "the values in the \"level\" column, to make a new data frame, `top_religion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_religion = ...\n",
    "top_religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_02_top_religion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us restrict our attention to the Rescuers and the Actives, for the moment.\n",
    "Make a new table `rescuers_actives` that contains only the first two columns of\n",
    "`top_religion`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescuers_actives = ...\n",
    "rescuers_actives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_03_rescuers_actives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Superficially, it looks as if there is a greater tendency for Rescuers to be\n",
    "Very or Somewhat religious, than is the case for Actives.\n",
    "\n",
    "Could this tendency have come about by chance?  How could we address this?\n",
    "\n",
    "Let us first extend the technique that we used in the [noble politics](https://matthew-brett.github.io/cfd2020/chapters/07/noble_politics) notebook.\n",
    "\n",
    "We will assume a model world in which we have the same total number of\n",
    "rescuers as we see here, and the same total number of actives.\n",
    "\n",
    "We also have the same total numbers of people who are \"Very\", \"Somewhat\", \"Not very\" and \"Not at all\" religious.\n",
    "\n",
    "However, in this model world, there is no difference in the tendency of\n",
    "Rescuers and Actives to give any of the four levels of religiousness.  For\n",
    "example, in this world, a Rescuer is just as likely as an Active to answer\n",
    "\"Very\".\n",
    "\n",
    "To simulate this world, we could put 65 + 9 = 74 pieces of paper with \"Very\"\n",
    "written on them into a hat, along with 79 + 17 = 96 pieces of paper with\n",
    "\"Somewhat\" written on them, and so on.  Then we shake up the hat, and, for each\n",
    "of the 210 Rescuers we draw one piece of paper out of the hat, tabulate the\n",
    "result (Rescuer associated with \"Very\", or \"Somewhat\", etc), and put the piece\n",
    "of paper aside.  Similarly for the remaining 48 labels, that correspond to the\n",
    "Actives.  This gives us a new table of counts, where there is a random\n",
    "association between the group (Rescuer / Active) and Religiousness (Very,\n",
    "Somewhat, Not very, Not at all).\n",
    "\n",
    "Here is one trial in such a world:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "# Recreate the individual labels for group and religiousness.\n",
    "group = np.repeat(['rescuers', 'actives'], rescuers_actives.sum())\n",
    "religiousness = np.repeat(['Very', 'Somewhat', 'Not very', 'Not at all'],\n",
    "                         rescuers_actives.transpose().sum())\n",
    "# Shuffle the religiousness labels to give a random association.\n",
    "np.random.shuffle(religiousness)\n",
    "# Make, show fake table.\n",
    "fake_table = pd.crosstab(religiousness, group)\n",
    "fake_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look in particular at the value for Very and Actives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "actual_by_very = rescuers_actives.loc['Very', 'actives']\n",
    "actual_by_very"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the value from the fake table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "fake_by_very = fake_table.loc['Very', 'actives']\n",
    "fake_by_very"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this simulation *1000* times, to get 1000 samples of the Very, Actives number.\n",
    "\n",
    "**Careful**: if you run this simulation 10000 times, instead of 1000, it will\n",
    "take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "very_actives = ...\n",
    "# Show the first five values\n",
    "very_actives[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_04_very_actives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the next cell to plot a histogram of the `very_actives` values, and\n",
    "calculate the proportion of `very_actives` that are less than or equal to the\n",
    "value we observed in the original table.  You will need these for later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Plot a histogram of the very_actives values, calculate the proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume that we are interested in the idea that Rescuers tend to be more\n",
    "religious than Actives, on average.   We need some way of converting the\n",
    "categories -- Very; Somewhat; Not very; Not at all -- to a score of\n",
    "religiousness.\n",
    "\n",
    "Map the categories to numbers like this:\n",
    "\n",
    "* Very = 3\n",
    "* Somewhat = 2\n",
    "* Not very = 1\n",
    "* Not at all = 0\n",
    "\n",
    "For example, I can construct the scores for all 210 rescuers represented in the table with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "rescuer_counts = rescuers_actives.loc[:, 'rescuers']\n",
    "rescuer_scores = np.repeat([3, 2, 1, 0], rescuer_counts)\n",
    "rescuer_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean religiousness scores for rescuers is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rescuer_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the same recipe to reconstruct the 48 Actives scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_scores = ...\n",
    "active_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_05_active_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have the scores, you can do a permutation test.\n",
    "\n",
    "The observed mean difference in scores is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "observed = np.mean(rescuer_scores) - np.mean(active_scores)\n",
    "observed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run a simulation of 10000 trials where, for each trial, you:\n",
    "\n",
    "* mix up the scores for the Rescuers and the actives;\n",
    "* The number of Rescuers is 210.  Select 210 scores at random to be fake\n",
    "  Rescuer scores; the remainder are fake Actives scores;\n",
    "* calculate the difference in means between these two fake groups, and store it\n",
    "  in an array `fake_mean_diffs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_mean_diffs = ...\n",
    "# Show the first five values\n",
    "fake_mean_diffs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_06_fake_mean_diffs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the cell below to do a histogram of these values, and calculate the proportion of these fake values that are greater than or equal to the observed value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Use this cell to plot histogram and calculate proportion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the evidence you have here, what conclusion can you draw about the\n",
    "observed counts of self-ratings of religiousness, from `oliner_tab6_6.csv`?  Do\n",
    "you think the counts are compatible with random sampling, in a world where\n",
    "there is no association between being a rescuer or an active and the person's\n",
    "level of religiousness?  Justify your conclusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2,
    "manual_grade": true,
    "manual_problem_id": "religion_plausible"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "You're finished with the assignment!  Be sure to...\n",
    "\n",
    "- **run all the tests** (the next cell has a shortcut for that),\n",
    "- **Save and Checkpoint** from the \"File\" menu.\n",
    "- Finally, **restart** the kernel for this notebook, and **run all the cells**,\n",
    "  to check that the notebook still works without errors.  Use the\n",
    "  \"Kernel\" menu, and choose \"Restart and run all\".  If you find any\n",
    "  problems, go back and fix them, save the notebook, and restart / run\n",
    "  all again, before submitting.  When you do this, you make sure that\n",
    "  we, your humble markers, will be able to mark your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "split_at_heading": true,
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.1",
    "jupytext_version": "1.2.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
