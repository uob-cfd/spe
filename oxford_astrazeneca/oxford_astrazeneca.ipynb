{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Oxford AstraZeneca dilemma\n",
    "\n",
    "The Oxford-AstraZeneca (OxAZ) vaccine was the first for which we had a full\n",
    "published and peer-reviewed paper on the results of the phase 3 clinical trial.\n",
    "\n",
    "Phase 3 trials assess whether the vaccine is effective for preventing\n",
    "infection.\n",
    "\n",
    "There was an odd aspect to the OxAZ trial, where a proportion of the\n",
    "participants accidentally got a low first dose of the vaccine.  The data later\n",
    "suggested that giving this lower dose made the vaccine more effective.\n",
    "\n",
    "Here we will analyze the data from the OxAZ trial, and consider how confident\n",
    "we can be in this odd finding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Safe settings for Pandas.\n",
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# The OKpy testing system.\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('oxford_astrazeneca.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The trial data\n",
    "\n",
    "We are looking at the data from the [Oxford-Astrazeneca vaccine trial results\n",
    "paper](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)32661-1/)\n",
    "\n",
    "There were various arms of the study.  Here we are looking at the UK arm of\n",
    "the study called \"COV002\" in the paper.\n",
    "\n",
    "Each arm had two groups.  One group got the new Coronavirus vaccine - we will\n",
    "call that the \"Covax\" group.  The other \"Control\" group got a control\n",
    "injection, that did not have the Coronavirus vaccine.  In fact, for the\n",
    "studies below, the control injection was a vaccine against an infection that\n",
    "causes meningitis.\n",
    "\n",
    "In each group, the subjects got two injections of their allocated type\n",
    "(\"Covax\" or \"Control\").  The paper calls the first and second injections the\n",
    "\"priming\" and \"booster\" doses, respectively.\n",
    "\n",
    "The planned Standard Dose (SD) of \"Covax\" was 50 billion viral particles.\n",
    "\n",
    "In fact, due to a mistake in the manufacturing and measurement process, some\n",
    "of the participants in the \"COV002\" arm got a priming dose that was about half\n",
    "the standard dose (SD);  the paper refers to this as the Low Dose (LD)\n",
    "injection.\n",
    "\n",
    "This meant that the COV002 arm became two arms, according to their first\n",
    "(priming) dose:\n",
    "\n",
    "1. LD priming / SD booster - \"LD/SD\" in the paper; we will call this \"LD\" for\n",
    "   short.\n",
    "2. SD priming / SD booster - \"SD/SD\"; \"SD\" for short.\n",
    "\n",
    "For various reasons, the LD group had a median time between priming and\n",
    "booster dose of 84 days, compared to a median of 69 days in the SD group.\n",
    "\n",
    "The interim analysis in the paper reports the number of symptomatic COVID-19\n",
    "cases in each group that occurred at least 14 days after the booster (second)\n",
    "injection.\n",
    "\n",
    "From data in table 2 of the paper, participants in the LD group had an average\n",
    "of 53.4 days of follow up, compared to 40.5 days in the SD group.\n",
    "\n",
    "Here are the data derived from table 2 of the paper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "ox_vax = pd.read_csv('ox_astra_cov002.csv')\n",
    "ox_vax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `N` column has the number of participants in the given Dose / Group, and\n",
    "`Cases` has the number of COVID-19 cases that occurred 14 days or more after\n",
    "the booster dose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the proportion of *all* participants that got COVID-19.\n",
    "\n",
    "*Hint* : consider the `sum` method of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_covid = ...\n",
    "prop_covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_prop_covid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function called `calc_prop_cases` that accepts a data frame like\n",
    "`ox_vax`, and returns the total number of `Cases`, divided by the total number\n",
    "in `N`. This is the proportion of cases in the group, for the given data\n",
    "frame.\n",
    "\n",
    "A \"data frame like `ox_vax`\" is a data frame that has columns `N` and `Cases`\n",
    "with the same meaning as for the `ox_vax` data frame.\n",
    "\n",
    "*Hint*: be very careful to use the data frame *like* `ox_vax` and not `ox_vax`\n",
    "itself inside your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prop_cases(df):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this function returns the same value as you calculated above, when\n",
    "# called on the whole table.\n",
    "calc_prop_cases(ox_vax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_calc_prop_cases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way of calculating the vaccine efficiency, it to calculate the drop in the\n",
    "risk of getting COVID-19 in the vaccine group, compared to the control.\n",
    "\n",
    "As you will see from the paper, we first calculate the *relative risk* (RR) of\n",
    "getting COVID-19 after the vaccine.  The RR is the *proportion* of people\n",
    "getting COVID-19 *after the vaccine* divided by the proportion of people\n",
    "getting COVID-19 *after the control*.\n",
    "\n",
    "Efficiency is 1 minus the relative risk (RR).\n",
    "\n",
    "*Hint* : You might want to use your function above.\n",
    "\n",
    "*Hint 2* : You will get a similar, but different number from the paper.  The\n",
    "paper is using some fancy adjustments for patient age and for number of days\n",
    "follow-up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_eff = 1 - ...\n",
    "vax_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_vax_eff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a function called `calc_efficiency` that returns the efficiency from\n",
    "a data frame like `ox_vax`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_efficiency(df):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check you get the same answer for the full data frame, as you calculated\n",
    "above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, check you get the same answer as previously.\n",
    "calc_efficiency(ox_vax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_calc_efficiency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting closer to our question of interest - does the LD dose arm show\n",
    "greater vaccine efficiency than the SD dose arm?\n",
    "\n",
    "Calculate the efficiency for the LD group; call this `ld_vax_eff`. Calculte\n",
    "the efficiency of the SD group; call this `sd_vax_eff`. Then subtract the SD\n",
    "from the LD efficiency to get an *efficiency difference*. Call this\n",
    "`vax_eff_diff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld_vax_eff = ...\n",
    "sd_vax_eff = ...\n",
    "vax_eff_diff = ...\n",
    "print('LD efficiency', ld_vax_eff)\n",
    "print('SD efficiency', sd_vax_eff)\n",
    "print('Efficiency difference', vax_eff_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_vax_eff_diff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see similar, but different estimates in the paper.   The difference\n",
    "looks fairly convincing, but our question, as ever, is whether these\n",
    "differences could have come about *as a result of random sampling*.\n",
    "\n",
    "Next make a function that called `calc_ld_sd_ediff` that accepts a data frame\n",
    "like `ox_vax` as an argument, and returns the difference in efficiency for the\n",
    "'LD' and 'SD' groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ld_sd_ediff(df):\n",
    "    ...\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check you get the same difference from this function as you did from your\n",
    "previous calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell, check you get the same answer as previously.\n",
    "calc_ld_sd_ediff(ox_vax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_calc_ld_sd_ediff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to think about whether the result could have come about by random\n",
    "sampling.\n",
    "\n",
    "In order to do this, we first make a table that re-creates the data on the\n",
    "individual participants to which the `ox_vax` data frame refers.\n",
    "\n",
    "We can do this because we know the number of participants in each *cell* of\n",
    "the study.  One *cell* refers to an unique combination of the \"LD\" / \"SD\"\n",
    "label and the \"Covax\" / \"Control\" label.  For example, the first cell is \"LD\"\n",
    "with \"Control\". We know from the data frame, that there are 1374 participants\n",
    "in this cell, of which 30 caught COVID-19.  We can reconstruct the individual\n",
    "patients for this cell by making 1374 rows, each with a \"Dose\" label of \"LD\",\n",
    "and a \"Group\" label of \"Control\".  The last column will be \"Case\", which is\n",
    "Boolean (True or False), where True corresponds to a subject who got COVID-19,\n",
    "and False to a subject who did not.   So, for this cell, we will have 1374 - 30\n",
    "= 1344 rows with False in the \"Case\" column, and 30 subjects with True in the\n",
    "\"Case\" column.\n",
    "\n",
    "The first five rows of the data frame will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the first five rows will look like.\n",
    "person_start = pd.DataFrame()\n",
    "person_start['Dose'] = np.repeat(['LD'], [5])\n",
    "person_start['Group'] = np.repeat(['Control'], [5])\n",
    "person_start['Case'] = np.repeat(['False'], [5])\n",
    "person_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick of course, is to do this for all four cells, so we have a new data\n",
    "frame with 1374 + 1367 + 1367 + 2377 = 6485 rows, one for each participant in\n",
    "the whole COV002 study.\n",
    "\n",
    "That is what you will do next.\n",
    "\n",
    "Here we get you started, by making the first column of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df = pd.DataFrame()\n",
    "n_per_cell = np.array(ox_vax['N'])\n",
    "person_df['Dose'] = np.repeat(['LD', 'LD', 'SD', 'SD'], n_per_cell)\n",
    "# Show the first five rows\n",
    "person_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now your turn.  Make the contents of the \"Group\" column and put that column into the `person_df` data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_df...\n",
    "# Show the first five rows so far.\n",
    "person_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_person_df_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we generate the False, True values for the \"Cases\" column.\n",
    "\n",
    "We suggest you use `np.repeat` for this.  As you know, the first argument to `np.repeat` is a sequence (such as a list) of things that will be repeated.  The second argument is the number of repeats for each element.\n",
    "\n",
    "We are going to repeat False 1374 - 30 = 1344 times, then True 30 times, and so\n",
    "on.  Here we are trying to help you by preparing the first argument for `np.repeat` - the False and True values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "# \"Case\" will be False for non-case, True for case.\n",
    "# Start with all False\n",
    "to_repeat = np.repeat([False], len(n_per_cell) * 2)\n",
    "# Set every other value, from the second, to True\n",
    "to_repeat[1:len(to_repeat):2] = True\n",
    "# Note that we can do the same thing with this short-cut.\n",
    "to_repeat[1::2] = True\n",
    "# Show the result\n",
    "to_repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your job is to prepare the second argument to `np.repeat`, the number of\n",
    "repeats, then use these arguments to fill in the \"Case\" column of `person_df`,\n",
    "to reconstruct the participants in the trial.\n",
    "\n",
    "*Hint*: be careful, your `repeat_nos` array below has to be of integer type,\n",
    "not float type, because the number of repeats has to be an integer.  It starts\n",
    "off that way, if you run the code we give you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with an integer array of zeros, of the right length.\n",
    "repeat_nos = np.repeat([0], len(to_repeat))\n",
    "...\n",
    "person_df['Case'] = ...\n",
    "# Show the first five rows.\n",
    "person_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_person_df_with_case')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'd like to check whether this table really does lead to the same counts for\n",
    "total numbers in each cell (\"N\") and the number of cases in each cell\n",
    "(\"Cases\"), as we had in the original.  Here we use some Pandas magic that we\n",
    "cover next term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a thing that knows how to \"group\" the rows \"by\" the pairs of labels in\n",
    "# \"Dose\" and \"Group\".\n",
    "grouped = person_df.groupby(['Dose', 'Group'])\n",
    "# Aggregate within these groups, by\n",
    "# * counting the number of rows\n",
    "#  (put this value into the column \"N\")\n",
    "# * counting the number of True values in the \"Case\" column\n",
    "#  (put this value into the column \"Cases\")\n",
    "aggregated = grouped.agg(N=('Case', len),\n",
    "                         Cases=('Case', np.count_nonzero))\n",
    "# Drop the fancy index (row labels) to make an ordinary data frame.\n",
    "tabulated = aggregated.reset_index()\n",
    "tabulated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function to do the same work.  It operates on a data frame like\n",
    "`person_df` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cases_to_counts(full_df):\n",
    "    \"\"\" Calculate \"N\" and \"Cases\" for \"Dose\" and \"Group\" cells of \"full_df\"\n",
    "    \"\"\"\n",
    "    return full_df.groupby(['Dose', 'Group']).agg(\n",
    "        N=('Case', len),\n",
    "        Cases=('Case', np.count_nonzero)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the function returns the original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should return values identical to the original \"ox_vax\" data frame.\n",
    "cases_to_counts(person_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually check the result is equal to the original table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should should evaluate to (and show) True.\n",
    "cases_to_counts(person_df).equals(ox_vax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we have `person_df` we can estimate the spread of the efficiency\n",
    "differences under random sampling.\n",
    "\n",
    "Let us formulate the null (ideal) world as - there is no real difference in the efficiency of the \"LD\" or \"SD\" doses.\n",
    "\n",
    "In such a world, the current \"LD\" and \"SD\" labels would be arbitrary.\n",
    "\n",
    "We can simulate what a sample would look like in such a world by taking a copy\n",
    "of the real `person_df` data frame, and doing a random permutation of the\n",
    "\"Dose\" labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df = person_df.copy()\n",
    "fake_df['Dose'] = np.random.permutation(person_df['Dose'])\n",
    "fake_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fake_df` is an example data frame drawn from the ideal (null) world.\n",
    "\n",
    "Try making 1000 such samples, and calculating the efficiency difference between the \"LD\" and \"SD\" doses for each one.  Record these fake differences in an array `fake_ediffs`.\n",
    "\n",
    "*Hint*: take 1000 samples, not more, otherwise your code will take too long to\n",
    "run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "fake_ediffs = ...\n",
    "# Show the first 10 efficiency differences.\n",
    "fake_ediffs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_fake_ediffs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your insight, show a histogram of the `fake_ediffs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Histogram of eff_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the proportion of efficiency differences in this null (ideal) world that are greater than or equal to one we observed in the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_ediff_ge = ...\n",
    "# Show the result\n",
    "prop_ediff_ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q_prop_ediff_ge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your analysis here, and on your reading of the paper, would you\n",
    "recommend that the UK go straight to using the LD/SD regimen for the OxAZ\n",
    "vaccine, or would you recommend the SD/SD regimen, or a mixture?  Give your\n",
    "reasons.\n",
    "\n",
    "NB - this answer counts for four times as many points are each of the previous\n",
    "answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "manual_grade": true,
    "manual_problem_id": "ox_az_recommend"
   },
   "source": [
    "*Write your answer here, replacing this text.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done.\n",
    "\n",
    "Congratulations, you're done with the assignment!  Be sure to:\n",
    "\n",
    "- **run all the tests** (the next cell has a shortcut for that).\n",
    "- **Save and Checkpoint** from the `File` menu.\n",
    "- Finally, **restart** the kernel for this notebook, and **run all the cells**,\n",
    "  to check that the notebook still works without errors.  Use the\n",
    "  \"Kernel\" menu, and choose \"Restart and run all\".  If you find any\n",
    "  problems, go back and fix them, save the notebook, and restart / run\n",
    "  all again, before submitting.  When you do this, you make sure that\n",
    "  we, your humble markers, will be able to mark your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For your convenience, you can run this cell to run all the tests at once!\n",
    "import os\n",
    "_ = [ok.grade(q[:-3]) for q in os.listdir(\"tests\") if q.startswith('q')]"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_json": true,
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true,
   "text_representation": {
    "extension": ".Rmd",
    "format_name": "rmarkdown",
    "format_version": "1.2",
    "jupytext_version": "1.6.0"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
